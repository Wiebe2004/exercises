{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Exploratory Data Analysis</h1>\n",
    "\n",
    "We're going to do some data exploration. For that, we'll need some date. You can find a video game dataset, among 200k other public datasets, available to download at <a href=\"https://www.kaggle.com/datasets/arnabchaki/popular-video-games-1980-2023?resource=download\">Kaggle</a>. We've already downloaded it for you and you'll find it, named *games.csv*, in the 07-data-processing folder.\n",
    "\n",
    "We will need to install some new libraries for this analysis: pandas and seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "\n",
    "#import the libraries we'll be using\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Read the dataset</h3>\n",
    "Pandas is a library for working with data, you'll encounter it in nearly any python data analysis project. Here we will use the read_csv() function to create a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../games.csv\"\n",
    "data = pd.read_csv(filepath,index_col = 0)\n",
    "# index_col is just indicating that there is a row number stored in the first column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preview the data</h3>\n",
    "\n",
    "You can use the head() function to view the column headers and first few rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape member gives the number of rows and columns in the entire dataframe. The info() function gives us some information about the columns. Here it's not particularly interesting, but we can see, for example that the rating is a numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Missing Values</h3>\n",
    "\n",
    "Notice the column above labeled \"Non-Null Count\". See how most columns have 1512 non-null values and this is the number of entries in the dataframe. So those columns are not missing any values.\n",
    "\n",
    "Note how Team and Rating have fewer than 1512 non-null values? We can display this a bit more clearly with a more custom-built table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_null = data.isnull().sum().sort_values(ascending = False)\n",
    "percent = ((data.isnull().sum()/data.isnull().count())*100).sort_values(ascending = False)\n",
    "print(\"Total records = \", data.shape[0])\n",
    "\n",
    "missing_data = pd.concat([total_null,percent.round(2)],axis=1,keys=['Total Missing','In Percent'])\n",
    "missing_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manually replace those missing values. This prevents that they will cause problems with our calculations later. You'll learn more about replacing missing values in Machine Learning and Data Analytics next year.\n",
    "\n",
    "For now, we'll replace a missing rating with the average of all ratings; we can use the mean function to calculate that. And we'll replace missing text from Team and Summary by \"Unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rating = data['Rating'].mean()\n",
    "\n",
    "data['Rating'] = data['Rating'].replace(np.nan, mean_rating)\n",
    "data['Team'] = data['Team'].replace(np.nan, \"['Unknown Team']\")\n",
    "data['Summary'] = data['Summary'].replace(np.nan, 'Unknown Summary')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recreate our table from above to check our replacements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_null = data.isnull().sum().sort_values(ascending = False)\n",
    "percent = ((data.isnull().sum()/data.isnull().count())*100).sort_values(ascending = False)\n",
    "print(\"Total records = \", data.shape[0])\n",
    "\n",
    "missing_data = pd.concat([total_null,percent.round(2)],axis=1,keys=['Total Missing','In Percent'])\n",
    "missing_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've successfully replaced all the missing values.\n",
    "\n",
    "<h3>Finding Duplicates</h3>\n",
    "\n",
    "There are also functions for finding and removing duplicate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = data[data.duplicated()]\n",
    "\n",
    "duplicates.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're a bit lucky here, because some of the duplicated rows are also present in the head() we saw at the beginning. So we can compare easily and see that Elden Ring at line 0 and line 326 is indeed the same data. Since we're going to drop these from the original dataframe, we can store them here in their own dataframe. IN reality, this is likely unnecessary since we don't have any need to work further with the duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're down to 1130 rows instead of the original 1512.\n",
    "\n",
    "Next we'd like to represent the Release Date as a DateTime instead of a string. This allows us to order things chronologically for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the date column to a datetime object\n",
    "data['Release Date'] = pd.to_datetime(data['Release Date'])\n",
    "\n",
    "# get the day from the date column\n",
    "data['Day'] = data['Release Date'].dt.day\n",
    "data['Month'] = data['Release Date'].dt.strftime('%b')\n",
    "data['Year'] = data['Release Date'].dt.year\n",
    "data['Week day'] = data['Release Date'].dt.day_name()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! Something went wrong. See the ValueError at the bottom of the output.\n",
    "\n",
    "\"ValueError: time data \"releases on TBD\" doesn't match format \"%b %d, %Y\", at position 423.\"\n",
    "\n",
    "So there are some entries in our dataframe that have not (or had not at the time this dataset was scraped) been released. We obviously can't parse a DateTime object out of \"releases on TBD\".\n",
    "\n",
    "<h3>Cleaning the Data</h3>\n",
    "\n",
    "Just like we replaced the missing values (nan) above, we can also replace these TBD dates. For simplicity, we can simply set them to today's date (or some future date if you prefer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a datetime object with the current time\n",
    "dt = datetime.now()\n",
    "# convert the datetime object to a string\n",
    "dt_str = dt.strftime('%b %d, %Y')\n",
    "# replace the TBD dates to the current date string\n",
    "data['Release Date'] = data['Release Date'].str.replace('releases on TBD', dt_str )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the date column to a datetime object\n",
    "data['Release Date'] = pd.to_datetime(data['Release Date'])\n",
    "\n",
    "# add columns for Day, Month, and Year based on the Release Date Column data\n",
    "data['Day'] = data['Release Date'].dt.day\n",
    "data['Month'] = data['Release Date'].dt.strftime('%b')\n",
    "data['Year'] = data['Release Date'].dt.year\n",
    "\n",
    "# add a Week Day column with the day of the week that the game was released on\n",
    "data['Week day'] = data['Release Date'].dt.day_name()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have another look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you recall, Rating is already a numeric value, but Times Listed, Number of Reviews, and others are not. Since we'd like to be able to analyze these, we can also covert these to numeric datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K represents 1000 so we multiply by 1000 in all these columns\n",
    "\n",
    "data['Times Listed'] = data['Times Listed'].str.replace('K', '').astype(float) * 1000\n",
    "data['Number of Reviews'] = data['Number of Reviews'].str.replace('K', '').astype(float) * 1000\n",
    "data['Plays'] = data['Plays'].str.replace('K', '').astype(float) * 1000\n",
    "data['Playing'] = data['Playing'].str.replace('K', '').astype(float) * 1000\n",
    "data['Backlogs'] = data['Backlogs'].str.replace('K', '').astype(float) * 1000\n",
    "data['Wishlist'] = data['Wishlist'].str.replace('K', '').astype(float) * 1000\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Descriptive Statistics</h3>\n",
    "\n",
    "Now that we have converted our strings to numeric values, we can easily compute some descriptive statistics. In fact, pandas provides a describe() function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Text Variables</h3>\n",
    "\n",
    "Have a look again at the data.head() output from earlier. Notice how Team, Genres, and Reviews can have multiple values for a single entry. These columns are actually stored as lists so more than one Team or more than one Genre can be attached to the same game.\n",
    "\n",
    "Pandas has an explode() function to create separate rows (each with the same index) to represent the multiple values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Team'] = data['Team'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# create a sample DataFrame with a column containing multiple values\n",
    "df_team = pd.DataFrame({\n",
    "    'Title': data['Title'].tolist(),\n",
    "    'Team': data['Team'].tolist()\n",
    "})\n",
    "# use the explode method to transform the 'Team' column\n",
    "df_team = df_team.explode('Team')\n",
    "df_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Genres'] = data['Genres'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# create a sample DataFrame with a column containing multiple values\n",
    "df_genres = pd.DataFrame({\n",
    "    'Title': data['Title'].tolist(),\n",
    "    'Genres': data['Genres'].tolist()\n",
    "})\n",
    "# use the explode method to transform the 'Team' column\n",
    "df_genres = df_genres.explode('Genres')\n",
    "df_genres"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Visualization</h3>\n",
    "\n",
    "A Histogram, also called a Distribution graph, shows how many entries (or rows) have a certain value or range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rating = data[['Title','Rating']].sort_values(by = 'Rating', ascending = False)\n",
    "\n",
    "sns.histplot(data = data['Rating'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the histogram generated above, what are some conclusions you can make about video game ratings?\n",
    "\n",
    "Things to consider:\n",
    "* Are video game ratings evenly spread across the possible ratings or seem to follow a pattern?\n",
    "* Video games tend to be rated around what value?\n",
    "\n",
    "\n",
    "Remember how we used explode() to break out the multiple genres for each game. We can use that to show how many of each genre there are. Then plot them in a bar graph or pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_genres = pd.DataFrame(df_genres['Genres'])\n",
    "count_genres = list_genres.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_genres = list_genres.value_counts().plot(kind='pie')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels get a bit messy here. We can make the chart bigger and move the labels to a legend or leave off some of the less popular genres. Which do you prefer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts = pd.DataFrame(list_genres.value_counts().rename_axis('unique_values'))\n",
    "genre_counts\n",
    "\n",
    "#plot = genre_counts.plot(kind = 'pie', labels = None, y='count', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlist_genres = pd.DataFrame(list_genres.value_counts().head(10))\n",
    "shortlist_plot = list_genres.value_counts().head(10).plot(kind='pie')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth mentioning, there are criticsms about pie charts in general. Humans aren't very good at determining angles and comparing pie slices. For more discussion on this topic, you can read <a href=\"https://www.data-to-viz.com/caveat/pie.html\">The Issue With the Pie Chart</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Bivariate Analysis or Correlations</h3>\n",
    "\n",
    "So far, we've focused on univariate analysis, that is, looking at one variable or column at a time. How many of each genre? What's the average rating? etc.\n",
    "\n",
    "The next step is to look at how two variables seem to be related to each other. Which genres are played by more players? Is there a relationship between the number of reviews and the average rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlist_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sample DataFrame with a column containing multiple values\n",
    "plays_genre_df = pd.DataFrame({\n",
    "    'Title': data['Title'].tolist(),\n",
    "    'Genres': data['Genres'].tolist(),\n",
    "    'Plays': data['Plays'].tolist(),\n",
    "    'Playing': data['Playing'].tolist()\n",
    "})\n",
    "# use the explode method to transform the 'Genres' column\n",
    "plays_genre_df = plays_genre_df.explode('Genres')\n",
    "\n",
    "top10genres = ['Adventure','RPG','Shooter','Platform','Indie','Puzzle','Strategy','Brawler','Simulator','Turn Based Strategy']\n",
    "\n",
    "plays_genre_df = plays_genre_df.groupby('Genres')[['Plays', 'Playing']].sum().reset_index()\n",
    "plays_genre_df = plays_genre_df.loc[plays_genre_df['Genres'].isin(top10genres)]\n",
    "plays_genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = plays_genre_df['Genres'].tolist()\n",
    "value1 = plays_genre_df['Plays'].tolist()\n",
    "value2 = plays_genre_df['Playing'].tolist()\n",
    "\n",
    "# Create a horizontal stacked bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "bar_width = 0.35\n",
    "bar1 = ax.barh(index, value1, bar_width, label='Plays', color='#4c72b0')\n",
    "bar2 = ax.barh(index, value2, bar_width, left=value1, label='Playing', color='#4cbdc9')\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel('Number of players')\n",
    "ax.set_ylabel('Genres')\n",
    "ax.set_title('Number of players for each genre', fontweight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task</h2>\n",
    "Choose a dataset on a topic that's interesting to you. You can search on <a href=\"https://www.kaggle.com/datasets\">Kaggle</a> or another public data repository. Create an Exploratory Data Analysis (what we've done here) of your own."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
